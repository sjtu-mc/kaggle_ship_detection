{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "output_path = 'output_201902132137/'\n",
    "weight_save_path = \"output_201902132137/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from skimage.io import imread\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "ship_dir = '../ship_detection/data'\n",
    "train_image_dir = os.path.join(ship_dir, 'train_v2')\n",
    "test_image_dir = os.path.join(ship_dir, 'test_v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_image_gen(in_df, batch_size = BATCH_SIZE):\n",
    "    all_batches = list(in_df.groupby('ImageId'))\n",
    "    out_rgb = []\n",
    "    out_mask = []\n",
    "    while True:\n",
    "        np.random.shuffle(all_batches)\n",
    "        for c_img_id, c_masks in all_batches:\n",
    "            rgb_path = os.path.join(train_image_dir, c_img_id)\n",
    "            c_img = imread(rgb_path)\n",
    "            c_mask = np.expand_dims(masks_as_image(c_masks['EncodedPixels'].values), -1)\n",
    "            out_rgb += [c_img]\n",
    "            out_mask += [c_mask]\n",
    "            if len(out_rgb)>=batch_size:\n",
    "                yield np.stack(out_rgb, 0)/255.0, np.stack(out_mask, 0)\n",
    "                out_rgb, out_mask=[], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df = pd.read_csv('valid_df.csv')\n",
    "valid_gen = make_image_gen(valid_df)\n",
    "valid_x, valid_y = next(valid_gen)\n",
    "print(valid_x.shape, valid_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from segmentation_models import Unet\n",
    "\n",
    "seg_model = Unet('resnet34')\n",
    "\n",
    "weight_path = output_path+'seg_model_weights.best.hdf5'\n",
    "seg_model.load_weights(weight_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TTA_ModelWrapper():\n",
    "    \"\"\"A simple TTA wrapper for keras computer vision models.\n",
    "    Args:\n",
    "        model (keras model): A fitted keras model with a predict method.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def predict(self, X, verbose=1):\n",
    "        \"\"\"Wraps the predict method of the provided model.\n",
    "        Augments the testdata with horizontal and vertical flips and\n",
    "        averages the results.\n",
    "        Args:\n",
    "            X (numpy array of dim 4): The data to get predictions for.\n",
    "        \"\"\"\n",
    "        p0 = self.model.predict(X, verbose=verbose)\n",
    "        p1 = self.model.predict(np.fliplr(X),verbose=verbose)\n",
    "        p2 = self.model.predict(np.flipud(X),verbose=verbose)\n",
    "        p3 = self.model.predict(np.transpose(X,(0,2,1,3)),verbose=verbose)\n",
    "        p4 = self.model.predict(np.rot90(X,1,(1,2)),verbose=verbose)\n",
    "        p5 = self.model.predict(np.rot90(X,2,(1,2)),verbose=verbose)\n",
    "        p6 = self.model.predict(np.rot90(X,3,(1,2)),verbose=verbose)\n",
    "        p7 = self.model.predict(np.rot90(np.transpose(X,(0,2,1,3)),2),verbose=verbose)\n",
    "#         print(p7.shape)\n",
    "#         print(np.rot90(np.transpose(p7),2).shape)\n",
    "        p = (p0 +\n",
    "             (np.fliplr(p1)) +\n",
    "             (np.flipud(p2)) +\n",
    "             (np.transpose(p3,(0,2,1,3))) +\n",
    "             (np.rot90(p4,3,(1,2))) +\n",
    "             (np.rot90(p5,2,(1,2))) +\n",
    "             (np.rot90(p6,1,(1,2))) +\n",
    "             (np.rot90(np.transpose(p7,(0,2,1,3)),2))             \n",
    "             ) / 8\n",
    "        \n",
    "        return p\n",
    "    \n",
    "    def _expand(self, x):\n",
    "        return np.expand_dims(x, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tta_model = TTA_ModelWrapper(seg_model)\n",
    "pred_y = tta_model.predict(valid_x)\n",
    "\n",
    "print(pred_y.shape, pred_y.min(), pred_y.max(), pred_y.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize = (6, 6))\n",
    "ax.hist(pred_y.ravel(), np.linspace(0, 1, 20))\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_yscale('log', nonposy='clip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# src: https://www.kaggle.com/aglotero/another-iou-metric\n",
    "def iou_metric(y_true_in, y_pred_in, print_table=False):\n",
    "    labels = y_true_in\n",
    "    y_pred = y_pred_in\n",
    "    \n",
    "    true_objects = 2\n",
    "    pred_objects = 2\n",
    "\n",
    "    intersection = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=(true_objects, pred_objects))[0]\n",
    "\n",
    "    # Compute areas (needed for finding the union between all objects)\n",
    "    area_true = np.histogram(labels, bins = true_objects)[0]\n",
    "    area_pred = np.histogram(y_pred, bins = pred_objects)[0]\n",
    "    area_true = np.expand_dims(area_true, -1)\n",
    "    area_pred = np.expand_dims(area_pred, 0)\n",
    "\n",
    "    # Compute union\n",
    "    union = area_true + area_pred - intersection\n",
    "\n",
    "    # Exclude background from the analysis\n",
    "    intersection = intersection[1:,1:]\n",
    "    union = union[1:,1:]\n",
    "    union[union == 0] = 1e-9\n",
    "\n",
    "    # Compute the intersection over union\n",
    "    iou = intersection / union\n",
    "\n",
    "    # Precision helper function\n",
    "    def precision_at(threshold, iou):\n",
    "        matches = iou > threshold\n",
    "        true_positives = np.sum(matches, axis=1) == 1   # Correct objects\n",
    "        false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n",
    "        false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n",
    "        tp, fp, fn = np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n",
    "        return tp, fp, fn\n",
    "\n",
    "    # Loop over IoU thresholds\n",
    "    prec = []\n",
    "    if print_table:\n",
    "        print(\"Thresh\\tTP\\tFP\\tFN\\tPrec.\")\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        tp, fp, fn = precision_at(t, iou)\n",
    "        if (tp + fp + fn) > 0:\n",
    "            p = tp / (tp + fp + fn)\n",
    "        else:\n",
    "            p = 0\n",
    "        if print_table:\n",
    "            print(\"{:1.3f}\\t{}\\t{}\\t{}\\t{:1.3f}\".format(t, tp, fp, fn, p))\n",
    "        prec.append(p)\n",
    "    \n",
    "    if print_table:\n",
    "        print(\"AP\\t-\\t-\\t-\\t{:1.3f}\".format(np.mean(prec)))\n",
    "    return np.mean(prec)\n",
    "\n",
    "def iou_metric_batch(y_true_in, y_pred_in):\n",
    "    batch_size = y_true_in.shape[0]\n",
    "    metric = []\n",
    "    for batch in range(batch_size):\n",
    "        value = iou_metric(y_true_in[batch], y_pred_in[batch])\n",
    "        metric.append(value)\n",
    "    return np.mean(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "\n",
    "thresholds = np.linspace(0, 1, 50)\n",
    "ious = np.array([iou_metric_batch(valid_y, np.int32(pred_y > threshold)) for threshold in tqdm_notebook(thresholds)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_best_index = np.argmax(ious[9:-10]) + 9\n",
    "iou_best = ious[threshold_best_index]\n",
    "threshold_best = thresholds[threshold_best_index]\n",
    "plt.plot(thresholds, ious)\n",
    "plt.plot(threshold_best, iou_best, \"xr\", label=\"Best threshold\")\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.ylabel(\"IoU\")\n",
    "plt.title(\"Threshold vs IoU ({}, {})\".format(threshold_best, iou_best))\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from skimage.morphology import label\n",
    "\n",
    "tta_model = TTA_ModelWrapper(seg_model)\n",
    "def predict(img, path=test_image_dir):\n",
    "    c_img = imread(os.path.join(path, img))\n",
    "    c_img = np.expand_dims(c_img, 0)/255.0\n",
    "    cur_seg = tta_model.predict(c_img,0)\n",
    "    \n",
    "#     cur_seg = fullres_model.predict(c_img)[0]\n",
    "    cur_seg = np.array(np.round(cur_seg[0,:,:,:] > threshold_best), dtype=np.float32)\n",
    "#     cur_seg = binary_opening(cur_seg>0.99, np.expand_dims(disk(2), -1))\n",
    "    return cur_seg, c_img\n",
    "\n",
    "## Get a sample of each group of ship count\n",
    "samples = valid_df.groupby('ships').apply(lambda x: x.sample(1))\n",
    "fig, m_axs = plt.subplots(samples.shape[0], 4, figsize = (15, samples.shape[0]*4))\n",
    "[c_ax.axis('off') for c_ax in m_axs.flatten()]\n",
    "\n",
    "for (ax1, ax2, ax3, ax4), c_img_name in zip(m_axs, samples.ImageId.values):\n",
    "    first_seg, first_img = predict(c_img_name, train_image_dir)\n",
    "    ax1.imshow(first_img[0])\n",
    "    ax1.set_title('Image: ' + c_img_name)\n",
    "    ax2.imshow(first_seg[:, :, 0])\n",
    "    ax2.set_title('Model Prediction')\n",
    "    reencoded = masks_as_color(multi_rle_encode(first_seg[:, :, 0]))\n",
    "    ax3.imshow(reencoded)\n",
    "    ax3.set_title('Prediction Re-encoded')\n",
    "    ground_truth = masks_as_color(masks.query('ImageId==\"{}\"'.format(c_img_name))['EncodedPixels'])\n",
    "    ax4.imshow(ground_truth)\n",
    "    ax4.set_title('Ground Truth')\n",
    "    \n",
    "fig.savefig('validation.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "boat_df = pd.read_csv(\"../ship_detection/output/ship_detection_lafoss.csv\")\n",
    "boat_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_boat = boat_df.p_ship>0.5\n",
    "print('Found {} boats'.format(is_boat.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_paths = np.array(os.listdir(test_image_dir))\n",
    "print(len(test_paths), 'test images found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "\n",
    "def pred_encode(img, **kwargs):\n",
    "    cur_seg, _ = predict(img)\n",
    "    cur_rles = multi_rle_encode(cur_seg, **kwargs)\n",
    "    return [[img, rle] for rle in cur_rles if rle is not None]\n",
    "\n",
    "out_pred_rows = []\n",
    "for c_img_name in tqdm_notebook(boat_df.id[is_boat]):   #boat_df.id[is_boat]\n",
    "    out_pred_rows += pred_encode(c_img_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.DataFrame(out_pred_rows)\n",
    "sub.columns = ['ImageId', 'EncodedPixels']\n",
    "sub = sub[sub.EncodedPixels.notnull()]\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub1 = pd.read_csv('../data/sample_submission_v2.csv')\n",
    "sub1 = pd.DataFrame(np.setdiff1d(sub1['ImageId'].unique(), sub['ImageId'].unique(), assume_unique=True), columns=['ImageId'])\n",
    "sub1['EncodedPixels'] = None\n",
    "print(len(sub1), len(sub))\n",
    "\n",
    "sub = pd.concat([sub, sub1])\n",
    "print(len(sub))\n",
    "\n",
    "sub.to_csv(output_path+'submission'+'.csv', \n",
    "              index=False)\n",
    "sub.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:chaos]",
   "language": "python",
   "name": "conda-env-chaos-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
